# Intervalos de Confianza y Pruebas de Hip√≥tesis

Imagina que eres el gerente de un restaurante que acaba de lanzar un nuevo plato estrella y quieres saber si a tus clientes les gusta tanto como esperabas.

Despu√©s de varias semanas recogiste las opiniones de algunos clientes: les pediste que calificaran de 1 a 5 qu√© tan satisfechos quedaron.  

Ya sabes calcular promedios, medianas y varianzas (¬°bien hecho hasta aqu√≠ üéâ!), pero surge una nueva pregunta:  

> ¬øPodemos usar la muestra de clientes que respondieron para decir algo sobre **todos** los clientes del restaurante, incluso los que no alcanzamos a encuestar?

Aqu√≠ entran en juego dos herramientas de la estad√≠stica inferencial: **los intervalos de confianza** y **las pruebas de hip√≥tesis**.  

---

## Intervalos de Confianza

Imagina que lanzaste un nuevo plato al men√∫ y quieres saber si a los clientes realmente les gusta. No puedes preguntarle a cada comensal, pero s√≠ ofreces muestras del plato a algunos clientes y recoges sus calificaciones. Esas degustaciones te dan una pista, no la verdad absoluta, sobre la opini√≥n de toda la clientela. 

En la mayor√≠a de estudios sucede esto: se toma una muestra y se infiere informaci√≥n sobre la poblaci√≥n total. Esto es porque es muy dif√≠cil o costoso preguntar a todos los clientes.

![Poblaci√≥n vs muestra](img/muestra.png){ width="40%" }

Un intervalo de confianza funciona igual para un par√°metro (por ejemplo, el promedio de satisfacci√≥n): parte de la estimaci√≥n obtenida en la muestra (la "degustaci√≥n") y le a√±ade y quita un margen de error para formar un rango plausible. Dos puntos clave para entenderlo intuitivamente:

- Interpretaci√≥n pr√°ctica: cuando hablamos de un "IC 95%" describimos el m√©todo: si repitieras el muestreo muchas veces y construyeras intervalos con el mismo procedimiento, alrededor del 95% de esos intervalos incluir√≠an el valor verdadero desconocido. No quiere decir que exista un 95% de probabilidad de que este intervalo concreto lo contenga; el valor real es fijo y lo que cambia es el intervalo que construimos.

- *¬øQu√© influye en el ancho del intervalo?*

1. La dispersi√≥n de las calificaciones ‚Äî m√°s variabilidad ‚Üí intervalos m√°s anchos.
2. El tama√±o de la muestra ‚Äî m√°s clientes encuestados ‚Üí intervalos m√°s estrechos.
3. El nivel de confianza elegido ‚Äî mayor confianza ‚Üí intervalos m√°s amplios.

Visualiza esto como elegir el tama√±o de la degustaci√≥n y el margen de seguridad alrededor de tu estimaci√≥n: si usas un margen muy amplio te aseguras de cubrir el valor verdadero pero pierdes precisi√≥n; si eliges un margen muy estrecho ganas precisi√≥n pero aumentas la probabilidad de equivocarte.

En resumen: un intervalo de confianza te ofrece un rango razonable para la media poblacional (por ejemplo, la satisfacci√≥n real de todos los clientes), acompa√±ado de una medida expl√≠cita de cu√°nta confianza te da ese procedimiento si lo repitieras muchas veces.

### ¬øC√≥mo se construye?

El intervalo de confianza toma el promedio de tu muestra y le agrega un ‚Äúmargen de error‚Äù.  

Ese margen depende de dos cosas:  
- Qu√© tan variable son las opiniones (la desviaci√≥n est√°ndar).  
- Cu√°ntos clientes alcanzaste a encuestar (el tama√±o de la muestra).  

::: callout-tip
## F√≥rmula del intervalo
$$
IC_{95\%} = \bar{x} \pm Z \cdot \frac{s}{\sqrt{n}}
$$

- \( $\bar{x}$ \): promedio de la muestra  
- \( $s$ \): variabilidad de las opiniones  
- \( $n$ \): n√∫mero de clientes encuestados  
- \( $Z$ \): un n√∫mero fijo que depende del nivel de confianza (1.96 para 95%)  
:::

### Ejemplo del restaurante

Encuestaste a **50 clientes**.  
El promedio de satisfacci√≥n fue **4.2** y la desviaci√≥n est√°ndar **0.8**.

$$
IC_{95\%} = 4.2 \pm 1.96 \cdot \frac{0.8}{\sqrt{50}} \approx (4.0,\;4.4)
$$

Esto significa que, aunque no hablamos con todos los clientes, podemos decir con un 95\% de confianza que la satisfacci√≥n promedio real de *todos* los comensales est√° entre **4.0 y 4.4**.

::: callout-tip
**En otras palabras un intervalo de confianza dice:**

**No estoy 100\% seguro de la cifra exacta, pero tengo un rango muy confiable donde debe estar el promedio verdadero si pudi√©ramos preguntar a todos los clientes.**

:::

---

## Pruebas de Hip√≥tesis

Ahora imagina otra situaci√≥n: tTu socio del restaurante es un poco esc√©ptico y te dice:  
> ‚Äú*Yo creo que los clientes nos califican, en promedio, con 4. Nada m√°s*.‚Äù  

T√∫, viendo tus datos, sospechas que en realidad el promedio es **mayor** a 4.  

¬øC√≥mo decidir qui√©n tiene raz√≥n?

Aqu√≠ usamos una **prueba de hip√≥tesis**. Es como un juicio estad√≠stico:  

- Partimos de la **hip√≥tesis nula (H‚ÇÄ)**: lo que asumimos de entrada.  
- Luego vemos si hay suficiente evidencia en la muestra para rechazarla y quedarnos con la **hip√≥tesis alternativa (H‚ÇÅ)**.



### Pasos de la prueba

1. **Plantear hip√≥tesis**  
   - H‚ÇÄ: $\mu = 4$ (los clientes en promedio califican con 4).  
   - H‚ÇÅ: $\mu > 4$ (los clientes en promedio califican con m√°s de 4).  

2. **Elegir un nivel de significancia**  
   - Normalmente usamos 5% (Œ± = 0.05).  
   - Significa que aceptamos un 5% de riesgo de equivocarnos al rechazar H‚ÇÄ.  

3.  **Calcular el p-valor y tomar la decisi√≥n**

- Usamos el sofware de preferencia para calcular la prueba t y obtener el p-valor.
- Si $p < \alpha$ (por ejemplo $\alpha=0.05$) rechazamos H‚ÇÄ; si $p \ge \alpha$ no rechazamos H‚ÇÄ.

::: callout-note
Nota pr√°ctica: no necesitas calcular el p-valor a mano

La mayor√≠a de los paquetes estad√≠sticos calculan y reportan el p-valor autom√°ticamente:

- En R: `t.test(x, mu = 4)` devuelve la estad√≠stica, el p-valor y el intervalo de confianza.
- En Python (SciPy): `scipy.stats.ttest_1samp(x, 4)` devuelve la estad√≠stica t y el p-valor.
- En Excel: la herramienta de an√°lisis de datos o la funci√≥n T.TEST reportan p-valores.

Lo importante es entender qu√© mide el p-valor y c√≥mo interpretarlo, no hacer el c√°lculo manual cada vez.

:::

---

### Ejemplo del restaurante

Con los datos de antes ($\bar{x}=4.2,\; s=0.8,\; n=50$) podemos usar el concepto de *p-valor* para decidir si rechazar H‚ÇÄ.

Intuitivamente, el p-valor responde a la pregunta: si la hip√≥tesis nula fuera cierta (es decir, si no hubiera diferencia real y el verdadero promedio fuera 4), ¬øqu√© probabilidad hay de obtener un resultado igual o m√°s extremo que el observado? Para explicarlo paso a paso:

1. Sup√≥n por un momento que estamos persiguiendo un golpe de suerte: la hip√≥tesis nula es verdadera (p. ej. el nuevo plato no cambia la satisfacci√≥n, la media es 4).
2. Imagina la distribuci√≥n de todos los resultados posibles que podr√≠amos haber obtenido al repetir el experimento muchas veces bajo H‚ÇÄ. La mayor√≠a ser√≠an resultados modestos y no llamativos; unos pocos ser√≠an flukes (suertes raras) que parecen indicar un efecto.
3. Ubica nuestro resultado real dentro de esa distribuci√≥n: el p-valor es la fracci√≥n de resultados bajo H‚ÇÄ que ser√≠an tan o m√°s extremos que el nuestro.

Un p-valor peque√±o (por ejemplo, 0.03) significa que s√≥lo un peque√±o porcentaje de resultados falsos ser√≠an tan espectaculares; esa rareza sugiere que tal vez no sea un fluke y que haya un efecto real.

Aplicando esto a nuestros datos, el p-valor unilateral resultante es aproximadamente $p \approx 0.038$ (‚âà3.8\%). Es decir: si de verdad el promedio fuera 4, s√≥lo en ~3.8\% de las muestras obtendr√≠amos un resultado tan extremo por azar.

Regla de decisi√≥n: si $p < \alpha$ (por ejemplo $\alpha=0.05$), rechazamos H‚ÇÄ. Aqu√≠ $0.038 < 0.05$, por lo que la evidencia es lo suficientemente fuerte para rechazar H‚ÇÄ.

::: callout-tip
## Veredicto
Rechazamos H‚ÇÄ.  
Podemos afirmar que, en promedio, tus clientes est√°n **m√°s satisfechos** que el 4 que sospechaba tu socio.
:::

---

::: callout-note
Importante ‚Äî "rechazar" vs "aceptar" H‚ÇÄ

En estad√≠stica decimos que *rechazamos* la hip√≥tesis nula o *no la rechazamos*, pero no la *aceptamos* como verdadera. Intuitivamente es as√≠ porque la prueba est√° dise√±ada para buscar evidencia en contra de H‚ÇÄ: si la evidencia es fuerte, la descartamos; si no lo es, simplemente no tenemos base para descartarla.

Piensa en un juicio: la ausencia de pruebas suficientes para condenar no es una prueba de inocencia absoluta. Del mismo modo, que los datos no permitan rechazar H‚ÇÄ puede deberse a que H‚ÇÄ es plausible *o* a que la muestra es peque√±a o el test no tiene poder suficiente para detectar la diferencia (error tipo II). Por eso los cient√≠ficos hablan de "no rechazar" y complementan con tama√±o del efecto y poder del estudio.

:::

##  Comparando dos grupos: ¬øde verdad son diferentes?

> **Idea clave:** tener dos medias con valores distintos **no** implica autom√°ticamente que sean **estad√≠sticamente diferentes**.  
> Una diferencia peque√±a puede deberse al azar de a qui√©nes encuestamos, especialmente si las muestras son peque√±as o muy variables.

Imagina que tu restaurante tiene **dos sedes**:

- **Sede Norte**: acabas de implementar una capacitaci√≥n en servicio.
- **Sede Sur**: a√∫n no (sirve como comparaci√≥n).

Encuestas la satisfacci√≥n (1 a 5) de clientes en ambas sedes y obtienes:

- **Norte:** \($\bar{x}_N = 4.3$\), \($s_N = 0.7$\), \($n_N = 40$\)  
- **Sur:** \($\bar{x}_S = 4.1$\), \($s_S = 0.9$\), \($n_S = 45$\)

A simple vista **4.3 vs 4.1** luce mejor en Norte, ¬øpero alcanza para concluir que la capacitaci√≥n **elev√≥** la satisfacci√≥n? Vamos paso a paso.

### Prueba de dos medias (grupos independientes)

Cuando las personas encuestadas en un grupo **no** son las mismas del otro grupo (clientes distintos en cada sede), usamos una prueba de dos muestras **independientes**. Por defecto, usa la versi√≥n **Welch** (no asume varianzas iguales).

**Hip√≥tesis (bilateral):**

- \($H_0:\ \mu_N - \mu_S = 0$\)  (no hay diferencia real)

- \($H_1:\ \mu_N - \mu_S \neq 0$\) (s√≠ hay diferencia)


Para un nivel de significancia \($\alpha=0.05$\) (bilateral),
el **p-valor** bilateral es \($\approx 0.25$\): no hay evidencia suficiente para afirmar que las medias difieren. **No rechazamos \($H_0$\).**  

**Intervalo de confianza (95%) para \($\mu_N - \mu_S$\):**
$$
(0.2) \pm 1.99 \times 0.174 \;\approx\; (-0.15,\; 0.55)
$$
Como el **0** est√° dentro del intervalo, la diferencia podr√≠a ser nula.

::: callout-tip
## Lectura pr√°ctica
- Que la media de Norte sea 4.3 y la de Sur 4.1 **no basta** para declarar una mejora real.
- Con esta evidencia, **no podemos asegurar** que la capacitaci√≥n subi√≥ la satisfacci√≥n; necesitamos m√°s datos o un efecto m√°s grande.
:::

#### Decidir unilateral vs bilateral
- **Bilateral (\($\neq$\))** cuando buscas *cualquier* diferencia.  
- **Unilateral (> o <)** solo si **antes** de ver los datos** tienes una hip√≥tesis direccional clara (p. ej., ‚Äúla capacitaci√≥n **aumenta** la satisfacci√≥n‚Äù).  
 

### ¬øY si las muestras son las mismas personas? (Prueba pareada)

Otra historia t√≠pica del restaurante: encuestas a **los mismos clientes** **antes** y **despu√©s** de la capacitaci√≥n en la **Sede Norte**.  

Aqu√≠ cada persona funciona como su **propio control** ‚Üí usamos una prueba **pareada** (de medias de **diferencias**).

- Define \($d_i = \text{(despu√©s)} - \text{(antes)}$\).  
- Hip√≥tesis:
  - \($H_0: \mu_d = 0$\) (en promedio, no cambia)
  - \($H_1: \mu_d > 0$\) (en promedio, mejora)

**Ejemplo:** 30 clientes habituales,  
\($\bar{d} = 0.25$\) puntos, \($s_d = 0.50$\).  

Con \($\alpha=0.05$\) unilateral, esto **s√≠** es significativo (p \($\approx 0.01$\)).  

**Interpretaci√≥n:** en la *misma* sede y *mismas* personas, la satisfacci√≥n **aument√≥** tras la capacitaci√≥n.

::: callout-important
## ¬øIndependientes o pareadas?
- **Independientes:** Norte vs Sur (clientes **distintos** en cada sede).  
- **Pareadas:** Antes vs Despu√©s en **la misma** sede y **mismas** personas.
:::

---

### Checklist r√°pido para comparar dos medias

1. **Escenario:**  
   - ¬øIndependientes (Norte vs Sur) o Pareadas (Antes vs Despu√©s)?
2. **Direcci√≥n de la hip√≥tesis:**  
   - ¬øBuscas *cualquier* diferencia (bilateral) o una mejora concreta (unilateral)?


::: callout-tip
## Estad√≠sticamente vs. pr√°cticamente significativo
Un resultado puede ser estad√≠sticamente significativo pero **poco relevante** en la pr√°ctica (p. ej., mejora de 0.05 puntos en satisfacci√≥n con miles de encuestas).  
En decisiones de negocio, combina el resultado estad√≠stico con el **impacto real**.
:::


### En resumen

- Los **intervalos de confianza** son como dar un rango plausible para la verdadera satisfacci√≥n de todos los clientes.  

- Las **pruebas de hip√≥tesis** son como un juicio: partimos de una suposici√≥n y vemos si la evidencia la sostiene o la derrumba.  

Ambas herramientas permiten ir m√°s all√° de describir lo que vemos en los datos: nos ayudan a **inferir** sobre toda la poblaci√≥n de clientes del restaurante.